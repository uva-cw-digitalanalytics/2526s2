{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Warm-up challenges for week 4\n",
    "\n",
    "Now that we've seen how to clean in Pandas, it's time for you to apply this knowledge. This week has three preparatory challenges. Make sure to give it a try and complete all of them. \n",
    "\n",
    "Each challenge has two components:\n",
    "1. **Programming and interpretation**\n",
    "3. **Reflection**\n",
    "\n",
    "**Some important notes for the challenges:**\n",
    "1. These challenges are a warming up, and help you get ready for class. Make sure to give them a try on all of them. \n",
    "2. If you get an error message, try to troubleshoot it (using Google often helps). If all else fails, go to the next challenge (but make sure to give it a try).\n",
    "3. These challenges are ungraded, yet they help you prepare for the graded challenges in the portfolio. If you want to be efficient, have a look at what you need to do for the upcoming graded challenges and see how to combine the work.\n",
    "\n",
    "### Facing issues? \n",
    "\n",
    "We are constantly monitoring the issues on the GitHub to help you out. Don't hesitate to log an issue there, explaining well what the problem is, showing the code you are using, and the error message you may be receiving. \n",
    "\n",
    "**Important:** We are only monitoring the repository in weekdays, from 9.30 to 17.00. Issues logged after this time will most likely be answered the next day. \n",
    "\n",
    "\n",
    "### Using Markdown\n",
    "\n",
    "1. Make sure to combine code *and* markdown to answer all questions. Mention specifically the question (and question number) and the answer in markdown, relating to the code and the output of the code. For the graded challenges, failing to do so will impact the grade, as we will not be able to see whether you answered the question.\n",
    "2. For every line of code, please include a cell in MarkDown explaining what the code is expected to do.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting setup for the challenges\n",
    "\n",
    "We will use actual Twitter data for the challenges of this week. To do so, you need:\n",
    "* Twitter data available on OneDrive. \n",
    "* Sentiment analysis dataset available on OneDrive.\n",
    "\n",
    "*You can reuse the code you created for the DA3 challenges where you merged  Twitter data with the sentiment data and created a meaningful sentiment measure, and just continue from there. If you have not completed DA3, make sure to perform these steps for this assignment*.\n",
    "\n",
    "**All the challenges below are with Twitter data. Make sure to start your challenge by doing the basics of loading and inspecting the data, even if not specified in challenge itself.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 1\n",
    "\n",
    "In the tutorial of last week, we created a categorical variable using conditions. This week, we have seen how to create binary variables based on text applying simple Natural Language Processing and how to \"recode\" variables using conditions.\n",
    "\n",
    "### Programming challenge\n",
    "\n",
    "For this challenge, create two variables for the Twitter data based on the text column. They should be two **meaningful** categories for your data, and they can either be binary taking the value 0 (when the tweet is not of that category) or 1 (when the tweet is of that category) or categorical with multiple meaningful categories that a tweet can fall under.\n",
    "\n",
    "Make sure to explain (in MarkDown) what these variables are, and provide some descriptives when they are done.\n",
    "\n",
    "\n",
    "### Reflection\n",
    "\n",
    "When using digital analytics to answer questions and solve problems, multiple decisions have to be made at different stages of the project that may result in bias. This also applies to data collection and pre-processing. When collecting data, choices made can introduce bias into the data.  Data pre-processing, including creating categories can also be an additional source of bias. In fact, using Natural Language Processing for categorization of cases in our dataset (e.g., for categorizing tweets), we can reduce the complexity of the dataset and get a better picture of our data, but also introduce more layers of bias into it. \n",
    "\n",
    "Building on the layers of bias described by Eckhouse et al. (2019), reflect on the types of bias possibly introduced to your dataset due to choices made \n",
    "1) when collecting twitter data \n",
    "2) when creating categories it in this challenge.\n",
    "\n",
    "Please make sure to motivate your response, and provide specific examples\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 2\n",
    "\n",
    "### Programming challenge\n",
    "\n",
    "Propose and visualise the answer for a RQ that has the **number of retweets** as the dependent variable, and one of the categories you created as the independent variable. Justify your choices in the answer.\n",
    "\n",
    "In this answer, you need to:\n",
    "* Show descriptive statistics for the IV and the DV\n",
    "* Create one univariate visualisation for the IV\n",
    "* Create one univariate visualisation for the DV\n",
    "* Create one bivariate visualisation with the IV and DV in the same chart\n",
    "* Show the descriptives of the DV grouped by the IV and interpret them\n",
    "\n",
    "### Reflection\n",
    "\n",
    "Visualisations are very helpful in exploring your dataset and relations between variables. They are also commonly used in reporting towards different stakeholders as a tool to make the data understandable to a wider audience. However, visualisations can also be very misleading.  Looking at the visualisations discussed in the tutorial and the ones you have chosen in this challenge, reflect to what extent and in what way:\n",
    "1) The choices you made could lead to manipulation or incorrect conclusions\n",
    "2) How the usage of different charts or ways to visualize the data by others may lead to manipulation or incorrect conclusions\n",
    "\n",
    "For both 1) and 2), make sure to provide specific examples and motivate your response.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 3 \n",
    "\n",
    "### Programming challenge\n",
    "\n",
    "\n",
    "Propose and visualise the answer for a RQ that has the **sentiment** as the dependent variable, and one of the categories you created as the independent variable. Justify your choices in the answer.\n",
    "\n",
    "In this answer, you need to:\n",
    "* Show descriptive statistics for the IV and the DV\n",
    "* Create one univariate visualisation for the IV\n",
    "* Create one univariate visualisation for the DV\n",
    "* Create one bivariate visualisation with the IV and DV in the same chart\n",
    "* Show the descriptives of the DV grouped by the IV and interpret them\n",
    "\n",
    "\n",
    "### Reflection\n",
    "\n",
    "Imagine that you proceed with the dataset you have created to answer your research question and help and organization. In the next step, you will conduct your analysis and create a model to automatically predict the user interests (topics) and their sentiment about the topic. These predictions will be later used to determine which type of advertisement the user will see.  \n",
    "\n",
    "Looking at privacy and ethical issues when working with data of individuals (even when it is pseudonymized), reflect how applying such frameworks as the DEDA aid could mitigate them when you use the data you have prepared and what issues remain.Please motivate your response, and provide specific ethical issues and how they can(not) be mitigated by such frameworks.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
