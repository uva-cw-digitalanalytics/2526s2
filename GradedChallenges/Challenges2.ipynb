{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "refined-chapel",
   "metadata": {},
   "source": [
    "# Graded Challenges 2 (DA3 and DA4)\n",
    "\n",
    "Now that we've seen how Python works and and how to use Pandas, it's time for you to combine and apply this knowledge to analyse Twitter data on your selected organisation or topic. In this challenge, you will work with the Twitter data and will execute all the steps necessary for visualising answers to a simple research question.\n",
    "\n",
    "The challenge consists of three components:\n",
    "1. **Programming**\n",
    "2. **Interpretation**\n",
    "3. **Reflection**\n",
    "\n",
    "**Some important notes for the challenges:**\n",
    "1. While we of course like when you get all the answers right, the important thing is to exercise and apply the knowledge. So we will give some credit for challenges that may not be complete, as long as we see enough effort. The rubric (see Canvas) reflects this.\n",
    "2. You will deliver the challenges on Canvas. Make sure to follow the turning-in instructions. \n",
    "\n",
    "### Usage of AI-generated content\n",
    "\n",
    "In line with the course policies, it is **not allowed** to use AI-generated content to any explanations or text provided in MarkDown. This means that for **Interpretation** and **Reflection** students are **not allowed** to use any AI-generated content or AI-assisted tools. \n",
    "\n",
    "For **Programming**, however, AI-assisted tools may be helpful to understand how to solve some of the questions - as one may also use Google to search for solutions online (e.g., on StackOverflow or other websites). They can, therefore, be used for the programming part of this challenge exceptionally - and only for this part - unless otherwise noted in the question. It is however your responsibility to test and make sure that the solution works - and explain this, in your own words, in the interpretation section.\n",
    "\n",
    "### Facing issues? \n",
    "\n",
    "We are constantly monitoring the issues on the GitHub to help you out. Don't hesitate to log an issue there, explaining well what the problem is, showing the code you are using, and the error message you may be receiving. \n",
    "\n",
    "**Important:** We are only monitoring the repository in weekdays, from 9.30 to 17.00. Issues logged after this time will most likely be answered the next day. This means you should not wait for our response before submitting a challenge :-)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statutory-generation",
   "metadata": {},
   "source": [
    "## Programming challenge\n",
    "\n",
    "You will use your own selected dataset. To do so, you need to:\n",
    "\n",
    "* Use any data available in class (see Canvas).\n",
    "* Use sentiment analysis file available on OneDrive, or compute your own sentiment scores\n",
    "\n",
    "The aim of this challenge is to propose and visualize the answer to a RQ that takes sentiment as the dependent variable and some information about your social media data as independent variable. To be able to visualize the answer, you will need to take a number of steps described below.\n",
    "\n",
    "Propose a research question that has **sentiment** as dependent variable and some **categorization of your social media data** as independent variable. **Make sure to write down the RQ in your submission**.\n",
    "\n",
    "The categorization needs to be meaningful for sentiment. It can be based on any available information in your data. You will need to create the categories in one of the next steps.\n",
    "\n",
    "1. Load your dataset.\n",
    "\n",
    "2. Minimize and pseudonymize your dataset. *Tip: to minimize it, think what variable are necessary for you to answer your RQ.*\n",
    "\n",
    "3. For sentiment:\n",
    "    - If using Twitter and Sentistrength: merge your tweets dataset with sentiment so that you have a sentiment score for each tweet. *Tip: Check if the length of the dataframe generated by the merge makes sense.* \n",
    "    - If using other data/package like Vader: compute sentiment scores. \n",
    "\n",
    "4. Create one variable that operationalizes the sentiment (i.e., that somehow aggregates the information of it being positive or negative - or potentially neutral - into one single variable).\n",
    "\n",
    "5. Write a function that categorizes your textual data. Apply this function to your data.\n",
    "    - The function can use Natural Language Processing (and categorize them based on the content of the tweets or comments) or other rules (for example, categorize tweets based on engagement, authors etc.). \n",
    "    - The categorization can be binary (taking the value 0 (when the text is not of that category) or 1 (when the text is of that category) or categorical with multiple meaningful categories that a text can fall under, but needs to contain meaningful information about the texts. \n",
    "\n",
    "6. Visualise and provide descriptive statistics to answer your RQ: \n",
    "    - Show descriptive statistics for the IV (categorical variable) and the DV (sentiment)\n",
    "    - Create one univariate visualisation for the IV\n",
    "    - Create one univariate visualisation for the DV\n",
    "    - Create one bivariate visualisation with the IV and DV in the same chart\n",
    "    - Show the descriptives of the DV grouped by the IV and interpret them\n",
    "\n",
    "\n",
    "### Using MarkDown\n",
    "\n",
    "Make sure to combine code and markdown to answer these questions. Mention specifically the question (and question number) and the answer in markdown, relating to the code and the output of the code. Failing to do will impact the grade, as we will not be able to see whether you answered the question.\n",
    "\n",
    "*Wordcount: There is no maximum wordcount for this section.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "toxic-sitting",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84d60f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "372613cd",
   "metadata": {},
   "source": [
    "## Intepretation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260d1bc6",
   "metadata": {},
   "source": [
    "### Explaining your process\n",
    "\n",
    "Write a brief description explaining how you created or assembled the code (i.e., sources used, and how did you adjust the code). In this description, include a brief reflection of the main challenges you had during the process, and how you handled these challenges.\n",
    "\n",
    "*Wordcount: maximum of 200 words. Please inform the wordcount for this answer*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2bd387",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f6288025",
   "metadata": {},
   "source": [
    "### Explaining your code\n",
    "\n",
    "You used a lot of code above to answer the six questions. Select what you consider to be the three most important steps in the code, justify why they are important, and explain the commands being used. \n",
    "\n",
    "*Note: there are different correct answers to what the three most important steps of the code are. We want to understand your reasoning/justification for this, and will accept different answers depending on the logic and clarity of your argumentation*.\n",
    "\n",
    "*Wordcount: maximum of 200 words. Please inform the wordcount for this answer*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb6d6be",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9f6e94f1",
   "metadata": {},
   "source": [
    "### Quality assurance\n",
    "\n",
    "You are assembling code from different sources - some of it you learned in the tutorial, you may have reused code we provided, and in some cases you may have used different online sources. But how do you know that the code actually worked and delivered the expected results? Please explain how someone else can verify that the code worked (e.g., what should they look at) and which steps you built into the code for yourself to know that it worked (explicitly indicate at least three steps)\n",
    "\n",
    "*Wordcount: maximum of 200 words. Please inform the wordcount for this answer*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845cc750",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9f6e94f2",
   "metadata": {},
   "source": [
    "### Hypothetical question\n",
    "\n",
    "Humans speak in more than 7000 languages ([source](https://www.ethnologue.com/)). Roughly 45% of these languages are endangered today. In order to help preserve these languages, can we use the principles of generative LLMs and build chatbots that can have a conversation in an endangered language? Why/Why not? Explain with reasons.\n",
    "\n",
    "*Wordcount: maximum of 200 words. Please inform the wordcount for this answer*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1de6d3e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "proper-toyota",
   "metadata": {},
   "source": [
    "## Reflection\n",
    "\n",
    "You have used a real-life dataset that contains information posted by real users of a digital platform. In this reflection, we ask you to focus on ethical and privacy considerations stemming from using such data for digital analytics. Please discuss the privacy risks as introduced by Tucker (2019) involved when such data from an online platform users are used for digital analytics (for example, answering your research questions), and what data-related considerations - related to and beyond privacy - need to be taken into account when collecting and analyzing tweets (following the Data Ethics Decision Aid).\n",
    "\n",
    "*Wordcount: maximum 500 words. Please inform the wordcount in this section.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quiet-founder",
   "metadata": {},
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "2526s1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
