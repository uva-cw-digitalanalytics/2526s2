{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Warm-up challenges for week 3\n",
    "\n",
    "Now that we've seen how to clean in Pandas, it's time for you to apply this knowledge. This week has three preparatory challenges. Make sure to give it a try and complete all of them. \n",
    "\n",
    "Each challenge has two components:\n",
    "1. **Programming and interpretation**\n",
    "3. **Reflection**\n",
    "\n",
    "**Some important notes for the challenges:**\n",
    "1. These challenges are a warming up, and help you get ready for class. Make sure to give them a try on all of them. \n",
    "2. If you get an error message, try to troubleshoot it (using Google often helps). If all else fails, go to the next challenge (but make sure to give it a try).\n",
    "3. These challenges are ungraded, yet they help you prepare for the graded challenges in the portfolio. If you want to be efficient, have a look at what you need to do for the upcoming graded challenges and see how to combine the work.\n",
    "\n",
    "### Facing issues? \n",
    "\n",
    "We are constantly monitoring the issues on the GitHub to help you out. Don't hesitate to log an issue there, explaining well what the problem is, showing the code you are using, and the error message you may be receiving. \n",
    "\n",
    "**Important:** We are only monitoring the repository in weekdays, from 9.30 to 17.00. Issues logged after this time will most likely be answered the next day. \n",
    "\n",
    "\n",
    "### Using Markdown\n",
    "\n",
    "1. Make sure to combine code *and* markdown to answer all questions. Mention specifically the question (and question number) and the answer in markdown, relating to the code and the output of the code. For the graded challenges, failing to do so will impact the grade, as we will not be able to see whether you answered the question.\n",
    "2. For every line of code, please include a cell in MarkDown explaining what the code is expected to do.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting setup for the challenges\n",
    "\n",
    "We will again use  social media data for the challenges of this week. This means you need:\n",
    "* Twitter data available on OneDrive\n",
    "* Sentiment analysis results for your tweets available on OneDrive\n",
    "\n",
    "**All the challenges below are with this Twitter data. Make sure to start your challenge by doing the basics of loading and inspecting the data, even if not specified in challenge itself.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 1\n",
    "\n",
    "In the last tutorial, we have talked about the importance of data minimization and pseudonimization. Now you know it, we would like to ask you to prepare your social medoa dataset in this way.\n",
    "\n",
    "Imagine you are currently working on the following research question:\n",
    "\n",
    "To what extent does the sentiment expressed in a post/review/ad influence user engagement with it (defined yourself)?\n",
    "\n",
    "### Programming challenge\n",
    "\n",
    "Using social media data, load it  with ```pandas``` and\n",
    "1. Determine which variables are relevant for the research question (don't forget to include control variables that you think are relevant).\n",
    "2. Create a minimized dataset (dataset with only variables necessary to answer the research question).\n",
    "3. Make sure that the minimized dataset is pseudonymized (identifying information about users is removed from user-related columns and from text).\n",
    "\n",
    "\n",
    "### Reflection\n",
    "\n",
    "Tucker (2019) discusses privacy risks involved when data is used for artificial intelligence applications and digital analytics, namely *data persistance, repurposing and spillovers*. Select one of the risks and reflect to what extent such technical solutions as data minimization and pseudonimization can mitigate these risks. Is more needed to protect privacy of users?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 2\n",
    "\n",
    "For this challenge you will need to add sentiment scores to your data.\n",
    "For each Twitter dataset, there is a sentiment analysis file available. This file contains tweets in a language specified in the Tweet title, their IDs and their sentiment scores.\n",
    "For other datasets, you can use Vader, a sentiment analysis tool to compute sentiment scores of text (see tutorial.)\n",
    "\n",
    "### Programming challenge\n",
    "\n",
    "*If using Twitter data* Merge the sentiment analysis file with the selected Twitter data. Make sure to check whether the length of the dataframe generated by the merge makes sense.\n",
    "\n",
    "*If using other data* Compute sentiment scores using Vader.\n",
    "\n",
    "\n",
    "### Reflection\n",
    "Possler et al. (2019) describe different ways communication scientists can access digital trace data. Looking at the different ways they describe and the advantages and disadvantages they mention, reflect on the way the data have been collected. In what way is the data collection method limiting? What are the opportunities and challenges you see?  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 3\n",
    "\n",
    "For Twitter data, the sentiment analysis results has three interesting columns: ```neutral```,  ```positive```, and ```negative```. It is coming from the SentiStrength (http://sentistrength.wlv.ac.uk/) algorithm, trinary version.\n",
    "Alternatively, Vader also returns multiple scores ( ```neutral```,  ```positive```, ```negative``` and ```compound```). Documentation can be found here: (https://github.com/cjhutto/vaderSentiment). \n",
    "\n",
    "### Programming challenge\n",
    "\n",
    "1. Create one variable that summarizes the sentiment (i.e., that somehow aggregates the information of it being positive or negative - or potentially neutral - into one single variable)\n",
    "2. Describe the sentiment of your data (mean, SD, mode - select metrics that make sense depending on how you created the sentiment variable).\n",
    "3. Create a new dataframe taking a random sample of 15 entries from your dataset. \n",
    "\n",
    "*Tip1: Pandas makes it easy to run numerical operations across columns. Let's say that I want to multiply the value that is in column A by the value that is in column B and store it in column C... I can simply use:*\n",
    "```df['C'] = df['A'] * df['B']```\n",
    "\n",
    "*Tip2: Use ```df.sample``` that we learned in the last tutorial to take a random sample of your tweets.*\n",
    "\n",
    "### Reflection\n",
    "Looking at the 15 entries, how well did the analysis do? Would you say the sentiment scores are reliable? For the reflection, we would like to ask you to reflect on the implication of large-scale usage of sentiment analysis. What does the reliability mean for automated decision made based on sentiment analysis of different digital traces? What challenges and threats can you identify?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
